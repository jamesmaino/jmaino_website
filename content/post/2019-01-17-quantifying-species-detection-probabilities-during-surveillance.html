---
title: Tutorial on quantifying species detection probabilities during surveillance with stan in R
author: ~
date: '2019-01-17'
slug: tutorial-on-quantifying-species-detection-probabilities-during-surveillance
categories: []
tags: ["bayesian", "stan", "monitorring", "resistance", "biosecurity", "exponential", "logistic", "R"]
header:
  caption: 'Quantifying detection of eggs'
  image: 'eastereggs.jpg'
---



<p>A practical question in species surveillance is “How much search effort is required for detection?”. This can be quantified under controlled conditions where the number and location of target species are known and participants are recruited to see how success rate varies.</p>
<p>Let’s use an example of an easter egg hunt where the adult (the researcher) wants to quantify how much effort it takes a child (the participant) to find an easter egg. Imagine that we let each child complete the easter egg course, and it is reset to the same condition before each new child.</p>
<pre class="r"><code>library(tidyverse)
library(rethinking)</code></pre>
<p>Here is a data summary of a such a trial <a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
<table>
<thead>
<tr class="header">
<th align="right">participant</th>
<th align="left">experience</th>
<th align="right">search_time_h</th>
<th align="right">area_searched_ha</th>
<th align="right">search_effort_h_ha</th>
<th align="right">no_sets_encountered</th>
<th align="right">no_sets_detected</th>
<th align="right">percent_detected</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">4</td>
<td align="left">yes</td>
<td align="right">1.67</td>
<td align="right">0.29</td>
<td align="right">5.69</td>
<td align="right">4</td>
<td align="right">4</td>
<td align="right">100</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="left">yes</td>
<td align="right">2.17</td>
<td align="right">0.25</td>
<td align="right">8.84</td>
<td align="right">6</td>
<td align="right">5</td>
<td align="right">83</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">yes</td>
<td align="right">1.42</td>
<td align="right">0.45</td>
<td align="right">3.14</td>
<td align="right">8</td>
<td align="right">5</td>
<td align="right">63</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="left">no</td>
<td align="right">1.08</td>
<td align="right">0.42</td>
<td align="right">2.57</td>
<td align="right">5</td>
<td align="right">3</td>
<td align="right">60</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="left">no</td>
<td align="right">1.00</td>
<td align="right">0.90</td>
<td align="right">1.11</td>
<td align="right">13</td>
<td align="right">7</td>
<td align="right">54</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="left">yes</td>
<td align="right">1.42</td>
<td align="right">0.84</td>
<td align="right">1.69</td>
<td align="right">15</td>
<td align="right">5</td>
<td align="right">33</td>
</tr>
<tr class="odd">
<td align="right">11</td>
<td align="left">yes</td>
<td align="right">1.07</td>
<td align="right">0.65</td>
<td align="right">1.64</td>
<td align="right">9</td>
<td align="right">3</td>
<td align="right">33</td>
</tr>
<tr class="even">
<td align="right">12</td>
<td align="left">no</td>
<td align="right">1.35</td>
<td align="right">0.20</td>
<td align="right">6.74</td>
<td align="right">3</td>
<td align="right">1</td>
<td align="right">33</td>
</tr>
<tr class="odd">
<td align="right">8</td>
<td align="left">yes</td>
<td align="right">0.92</td>
<td align="right">1.20</td>
<td align="right">0.77</td>
<td align="right">23</td>
<td align="right">7</td>
<td align="right">30</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="left">no</td>
<td align="right">1.00</td>
<td align="right">0.76</td>
<td align="right">1.32</td>
<td align="right">15</td>
<td align="right">4</td>
<td align="right">27</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="left">no</td>
<td align="right">1.28</td>
<td align="right">0.24</td>
<td align="right">5.43</td>
<td align="right">5</td>
<td align="right">1</td>
<td align="right">20</td>
</tr>
<tr class="even">
<td align="right">5</td>
<td align="left">yes</td>
<td align="right">1.17</td>
<td align="right">1.43</td>
<td align="right">0.81</td>
<td align="right">22</td>
<td align="right">2</td>
<td align="right">9</td>
</tr>
</tbody>
</table>
<p>This table shows some child level characteristics that might effect detection, such as whether or not they have had any prior experience looking for easter eggs. But suppose we want to control for some property of the hidden easter egg, such as the size of the egg in grams, where we might pressume that larger eggs are easier to find. Here I separate out the data into Bernoulli form (1s for detections and 0s for misses) and assign a random egg size between 10 and 100 g.</p>
<pre class="r"><code>set.seed(111) # fix random numbers
# convert summary data to long format (Bernoulli trials)
total_eggs = 23
db = d %&gt;%
  rowwise() %&gt;%
  mutate(detection = list(rep(c(0, 1), c(no_sets_encountered - no_sets_detected, no_sets_detected)))) %&gt;%
  dplyr::select(-no_sets_encountered,-no_sets_detected, -percent_detected) %&gt;%
  unnest() %&gt;%
  
  # assign id to eggs and then random size
  group_by(participant) %&gt;%
  mutate(egg_id = sample(1:total_eggs,n(),replace = FALSE)) %&gt;%
  ungroup %&gt;%
  mutate(egg_size = runif(total_eggs, 10,100)[egg_id]) %&gt;%
  mutate(experience = ifelse(experience == &#39;yes&#39;, 1, 0)) %&gt;%
  mutate(log_search_effort_h_ha = log(search_effort_h_ha)) %&gt;%
  
  # it is good practice to use centred variable (mean = 0) for parameter interpretation and fitting
  mutate(egg_size_c = egg_size - mean(egg_size)) %&gt;%
  as.data.frame
  
knitr::kable(head(db))</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">participant</th>
<th align="right">experience</th>
<th align="right">search_time_h</th>
<th align="right">area_searched_ha</th>
<th align="right">search_effort_h_ha</th>
<th align="right">detection</th>
<th align="right">egg_id</th>
<th align="right">egg_size</th>
<th align="right">log_search_effort_h_ha</th>
<th align="right">egg_size_c</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">4</td>
<td align="right">1</td>
<td align="right">1.67</td>
<td align="right">0.29</td>
<td align="right">5.69</td>
<td align="right">1</td>
<td align="right">14</td>
<td align="right">88.35757</td>
<td align="right">1.738710</td>
<td align="right">27.820235</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">1</td>
<td align="right">1.67</td>
<td align="right">0.29</td>
<td align="right">5.69</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">24.79464</td>
<td align="right">1.738710</td>
<td align="right">-35.742694</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="right">1</td>
<td align="right">1.67</td>
<td align="right">0.29</td>
<td align="right">5.69</td>
<td align="right">1</td>
<td align="right">11</td>
<td align="right">92.79748</td>
<td align="right">1.738710</td>
<td align="right">32.260140</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">1</td>
<td align="right">1.67</td>
<td align="right">0.29</td>
<td align="right">5.69</td>
<td align="right">1</td>
<td align="right">10</td>
<td align="right">56.31577</td>
<td align="right">1.738710</td>
<td align="right">-4.221572</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">1</td>
<td align="right">2.17</td>
<td align="right">0.25</td>
<td align="right">8.84</td>
<td align="right">0</td>
<td align="right">9</td>
<td align="right">65.42770</td>
<td align="right">2.179287</td>
<td align="right">4.890362</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="right">1</td>
<td align="right">2.17</td>
<td align="right">0.25</td>
<td align="right">8.84</td>
<td align="right">1</td>
<td align="right">22</td>
<td align="right">17.12628</td>
<td align="right">2.179287</td>
<td align="right">-43.411054</td>
</tr>
</tbody>
</table>
<p>So now that we have some characterics of the child (e.g. search effort), and each hidden egg (e.g. size) that are expected to affect detection probabilities it is time to model it.</p>
<p>Each encounter (<span class="math inline">\(X_{i,j}\)</span>) with an egg j by child i can be considered a draw from a Bernoulli distribution with parameter <span class="math inline">\(p_{i,j}\)</span>, which is the probability of detecting the egg given it was present:</p>
<p><span class="math display">\[X_{i,j} \sim \textrm{dbern}(p_{i,j})\]</span></p>
<p>The are many ways to model the probability of detection. One is to assume an exponential relationship with search effort where <span class="math inline">\(p_{i,j}\)</span> is given by:</p>
<p><span class="math display">\[p_{i,j} = 1 - exp(-\lambda_{i,j} f_j)\]</span></p>
<p>where <span class="math inline">\(f_i\)</span> is the search effort per unit area of child i, and <span class="math inline">\(\lambda_{i,j}\)</span> is the rate of detection of plant set j by observer i, modelled as a log-linear function of factors identified as likely to influence detectability or:</p>
<p><span class="math display">\[\ln(\lambda_{i,j}) = a + b.s_j + c.e_i + \textrm{obs}_i\]</span>
where <span class="math inline">\(a\)</span> is the intercept term, <span class="math inline">\(b\)</span> is the effect of egg size <span class="math inline">\(s_j\)</span>, and <span class="math inline">\(c\)</span> is the effect child experience <span class="math inline">\(e_i\)</span>. The reference level of child experience is ‘no experience’.</p>
<p>For an intuitive explanation of commonly used probability distributions, see <a href="/post/generating-probability-distribution-with-natural-examples">this previous post</a> and <a href="/post/bayesian-and-frequentist-logistic-regression-in-r">this one on bayesian vs. frequentist binomial responses</a>.</p>
<p>On to fitting. First, get some reasonable initial values for the model.</p>
<pre class="r"><code>a = 0.17  
b = 0.001
c = 0.125
db %&gt;% 
  mutate(pred =  1 - exp(-(a + b*egg_size_c + c*experience + log_search_effort_h_ha))) %&gt;% 
  dplyr::select(pred, detection) %&gt;%
  head</code></pre>
<pre><code>##        pred detection
## 1 0.8727409         1
## 2 0.8643894         1
## 3 0.8733047         1
## 4 0.8685973         1
## 5 0.9161878         0
## 6 0.9120402         1</code></pre>
<p>Then fit the model using Richard McElreath’s <code>rethinking</code> package and <code>rstan</code>. Note that we are kind of pushing the limits the syntax that the <code>rethinking</code> package can handle so there are a couple of errors when computing statisitics like the WAIC.</p>
<pre class="r"><code>m1 &lt;- rethinking::map2stan(
  alist(
    detection ~ dbinom( 1 , 1 - exp(-lambda_f) ),
    log(lambda_f) &lt;-  (a + b*egg_size_c + c*experience + log_search_effort_h_ha + obs[participant]),
    a ~ dnorm(0, 10),
    b ~ dnorm(0, 10),
    c ~ dnorm(0, 10),
    obs[participant] ~ dnorm(0, sigma) ,
    sigma ~ dcauchy(0,1)
  ),
  data = db, 
  start = list(a=0.17, b = 0.001, c=0.125, sigma = 0.3) ,
  chains=1 , iter=10000 , warmup=1000
  
)
save(m1, file = &#39;data/detection_prob/m1.Rdata&#39;)</code></pre>
<p>The precis output shows that 0.89 credible intervals excluded both the experience covariate and the randomly generated egg size covariate.</p>
<pre class="r"><code># summary output
precis(m1)</code></pre>
<pre><code>##        Mean StdDev lower 0.89 upper 0.89 n_eff Rhat
## a     -1.66   0.40      -2.30      -1.05  3198    1
## b      0.01   0.01       0.00       0.02  1824    1
## c      0.34   0.51      -0.48       1.08  3414    1
## sigma  0.56   0.31       0.07       0.94   490    1</code></pre>
<pre class="r"><code># plot detection probability vs. effort
pars = precis(m1)@output$Mean
names(pars) = rownames(precis(m1)@output)
obs = precis(m1, depth = 2)@output$Mean[5:16]
pred_line =  expand.grid(search_effort_h_ha = 10^seq(-1, 1, length = 100),
                         egg_size = c(60.5),
                         experience = 0:1, 
                         participant = 1) %&gt;% # placeholder participant
  mutate(log_search_effort_h_ha = log(search_effort_h_ha)) %&gt;%
  mutate(egg_size_c = egg_size - mean(db$egg_size))
# create matrix of zeros getting mean of random effect
participant_zeros = matrix(0, 1000, max(d$participant)) 
mu &lt;- link(m1, data=pred_line, replace=list(obs=participant_zeros))</code></pre>
<pre><code>## [ 100 / 1000 ]
[ 200 / 1000 ]
[ 300 / 1000 ]
[ 400 / 1000 ]
[ 500 / 1000 ]
[ 600 / 1000 ]
[ 700 / 1000 ]
[ 800 / 1000 ]
[ 900 / 1000 ]
[ 1000 / 1000 ]</code></pre>
<pre class="r"><code>pred_line$pred &lt;- 1 - exp(-apply( mu , 2 , mean ))
pred_line[,c(&#39;lower&#39;,&#39;upper&#39;)] &lt;- t(1 - exp(-apply(mu, 2, PI, prob = 0.89)))

# predictions for each participant with random effect (at mean egg size) 
d = d %&gt;%
  mutate(log_search_effort_h_ha = log(search_effort_h_ha)) %&gt;%
  mutate(pred = 1 - exp(-exp((pars[&#39;a&#39;] + pars[&#39;b&#39;]*0 + pars[&#39;c&#39;]*(experience==&#39;yes&#39;) + log_search_effort_h_ha + obs[participant]))))
p1 = ggplot(pred_line, aes(search_effort_h_ha, pred, colour = factor(experience))) +
  geom_line(aes(linetype = factor(experience))) +
  geom_line(aes(y=lower, linetype = factor(experience))) +
  geom_line(aes(y=upper, linetype = factor(experience))) +
  geom_ribbon(aes(ymin=lower,ymax=upper,fill = factor(experience), color = NULL), alpha = 0.2) +
  geom_point(data = d, aes(linetype = NULL), colour = &#39;white&#39;, shape = 1) +
  geom_point(data = d, aes(y = percent_detected/100), colour = &#39;white&#39;) +
  ylab(&#39;predicted detection probability&#39;) +
  xlab(&#39;search effort, h/ha&#39;) +
  guides(fill=F, colour = F, linetype = F) + 
  ggtitle(&#39;Model 1&#39;) +
  mydarktheme
cowplot::plot_grid( p1, p1 + ggtitle(&#39;&#39;)+ scale_x_log10(), ncol=2)</code></pre>
<p><img src="/post/2019-01-17-quantifying-species-detection-probabilities-during-surveillance_files/figure-html/unnamed-chunk-8-1.png" width="768" />
<strong>Figure 1.</strong> Plot of model 1 predicted detection probability as a function of search effort. Filled circles show observed detected percentages by each participant, while hollow circles show predicted probabilities for each observer’s measured effort level and fitted random effect (egg size is set to mean). Shaded regions shows 89% credible interval. Prediction for experienced individuals shown with blue (vs red for not-experienced).</p>
<p>In choosing to implement this model in stan, I found myself a world of hurt, which mostly resulted in pushing the <code>rethinking</code> package to its limits. I have never seen so many error messages as I fumbled my way through red words trying to make a log-link function work with a binomial regression (or some other way to restrict the value of <span class="math inline">\(\lambda\)</span> to positive values else break the contraint <span class="math inline">\(0&lt;p&lt;1\)</span>). Most of this stems from my lack of understanding around syntax in <code>stan</code> but this exercise has convinced me to invest more time to learn it properly and write models directly in stan. That said, <code>rethinking</code> is an excellent framework in which to learn and play around with Bayesian models.</p>
<p>All this pain taught me that binomial probabilities have to be between 0 and 1 and if you have some linear function <code>y = a + x * b</code>, which can take on any real value, then <code>1 - exp(-y)</code> is only bounded by 0 and 1 when y is positive, which is why we use the log-link function to restrict <code>y</code> (i.e. <code>exp(y) &gt; 0</code>). More conventionally, linear functions are converted to valid probabilities using the logit-link (i.e. <code>logit(y) = 1/(1 + y) &gt; 0</code>.</p>
<p>I explored this more conventional approach by using the <code>logit</code> link function which resulted in our previous linear function becoming framed around the log odds ratio <span class="math inline">\(\ln(\frac{p}{1-p})\)</span>. I ended up with a pretty similar model.</p>
<p><span class="math display">\[p_{i,j} = \frac{1}{1 + exp(-y_{i,j})}\]</span>
where</p>
<p><span class="math display">\[y_{i,j} = a + b.s_j + c.e_i + \log(f_i) + \textrm{obs}_i\]</span>
and the variables are defined as before.</p>
<p>Expressing the equation in terms of the odds ratio helps interpretabilty.</p>
<p><span class="math display">\[\frac{p}{1-p} = exp(a + b.s_j + c.e_i + \textrm{obs}_i)f_i\]</span></p>
<p>The odds of detection scales linearly with survey effort.</p>
<pre class="r"><code>m2 &lt;- rethinking::map2stan(
  alist(
    detection ~ dbinom( 1 , p ),
    logit(p) &lt;-  a + b*egg_size_c + c*experience + log_search_effort_h_ha + obs[participant]  ,
    a ~ dnorm(0, 10),
    b ~ dnorm(0, 10),
    c ~ dnorm(0, 10),
    obs[participant] ~ dnorm(0, sigma) ,
    sigma ~ dcauchy(0,1)
  ),
  data = db, 
  chains=1 , iter=10000 , warmup=1000
)
save(m2, file = &#39;data/detection_prob/m2.Rdata&#39;)</code></pre>
<p>Interestingly, model coefficients are similar despite the different link function.</p>
<pre class="r"><code># summarise model 
precis(m2)</code></pre>
<pre><code>##        Mean StdDev lower 0.89 upper 0.89 n_eff Rhat
## a     -1.25   0.50      -2.01      -0.47  3587    1
## b      0.01   0.01       0.00       0.02  7950    1
## c      0.31   0.64      -0.67       1.29  2964    1
## sigma  0.64   0.38       0.05       1.11   718    1</code></pre>
<pre class="r"><code># plot detection probability vs effort
pars = precis(m2)@output$Mean
names(pars) = rownames(precis(m2)@output)
obs = precis(m2, depth = 2)@output$Mean[4:16]
pred_line =  expand.grid(search_effort_h_ha = 10^seq(-1, 1, length = 100),
                         egg_size = c(60.5),
                         experience = 0:1,
                         participant = 1) %&gt;% # participant place holder
  mutate(egg_size_c = egg_size - mean(db$egg_size)) %&gt;%
  mutate(log_search_effort_h_ha = log(search_effort_h_ha))

# create matrix of zeros getting mean of random effect
participant_zeros = matrix(0, 1000, max(d$participant)) 
mu &lt;- link(m2, data=pred_line, replace=list(obs=participant_zeros))</code></pre>
<pre><code>## [ 100 / 1000 ]
[ 200 / 1000 ]
[ 300 / 1000 ]
[ 400 / 1000 ]
[ 500 / 1000 ]
[ 600 / 1000 ]
[ 700 / 1000 ]
[ 800 / 1000 ]
[ 900 / 1000 ]
[ 1000 / 1000 ]</code></pre>
<pre class="r"><code>pred_line$pred &lt;- (apply( mu , 2 , mean ))
pred_line[,c(&#39;lower&#39;,&#39;upper&#39;)] &lt;- t((apply( mu , 2 , PI, prob = 0.89 )))

# predictions for each participant with random effect (at mean egg size) 
d = d %&gt;%
  mutate(pred = (inv_logit(pars[&#39;a&#39;] + pars[&#39;b&#39;]*0 + pars[&#39;c&#39;]*(experience==&#39;yes&#39;) +log(search_effort_h_ha) + obs[participant])))
p2 = ggplot(pred_line, aes(search_effort_h_ha, pred, colour = factor(experience))) +
  geom_line(aes(linetype = factor(experience))) +
  geom_line(aes(y=lower, linetype = factor(experience))) +
  geom_line(aes(y=upper, linetype = factor(experience))) +
  geom_ribbon(aes(ymin=lower,ymax=upper,fill = factor(experience), color = NULL), alpha = 0.2) +
  geom_point(data = d, aes(linetype = NULL), colour = &#39;white&#39;, shape = 1) +
  geom_point(data = d, aes(y = percent_detected/100), colour = &#39;white&#39;) +
  ylab(&#39;predicted detection probability&#39;) +
  xlab(&#39;search effort, h/ha&#39;) +
  guides(fill=F, colour = F, linetype = F) + 
  ggtitle(&#39;Model 2&#39;) +
  mydarktheme

cowplot::plot_grid( p1 , p1 + ggtitle(&#39;&#39;) + scale_x_log10(),
                    p2 , p2 + ggtitle(&#39;&#39;) + scale_x_log10(), ncol=2)</code></pre>
<p><img src="/post/2019-01-17-quantifying-species-detection-probabilities-during-surveillance_files/figure-html/unnamed-chunk-13-1.png" width="768" /></p>
<p><strong>Figure 2.</strong> Plot of model 2 predicted detection probability as a function of search effort. Filled circles show observed detected percentages by each participant, while hollow circles show predicted probabilities for each observer’s measured effort level and fitted random effect (egg size is set to mean). Shaded regions shows 89% credible interval. Prediction for experienced individuals shown with blue (vs red for not-experienced).</p>
<p>The DIC of model 2 is lower than model 1.</p>
<pre class="r"><code>DIC(m1)[1]</code></pre>
<pre><code>## [1] 161.7463</code></pre>
<pre class="r"><code>DIC(m2)[1]</code></pre>
<pre><code>## [1] 160.9068</code></pre>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>This is real data but instead of easter eggs, participants were asked to survey for hawkweed in the Victorian alps. Data is from Moore, J. L., Hauser, C. E., Bear, J. L., Williams, N. S. and McCarthy, M. A. (2011), Estimating detection–effort curves for plants using search experiments. Ecological Applications, 21: 601-607. <a href="doi:10.1890/10-0590.1" class="uri">doi:10.1890/10-0590.1</a><a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
